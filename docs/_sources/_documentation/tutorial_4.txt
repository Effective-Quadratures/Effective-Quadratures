Computing moments
========================================

This tutorial raises a very important question. Why bother using polynomials for estimating moments? What exactly is the advantage? Moreover, are we guaranteed that we will converge to the Monte Carlo solution? The answer is a resounding yes! Infact this is precisely what Dongbin Xiu and George Karniandakis showed in their seminal paper [1]. As always we begin with some definitions: Parameter, Polyint and Basis. We will also incorporate the Statistics class.

.. code::
	
	from equadratures import *
	import numpy as np

For our model problem, let's consider Rosenbrock's function

.. math::

	f(x_1, x_2) = (1 - x_1)^2 + 100(x_1 - x_2^2)^2,

where we will assume that :math:`x_1` and :math:`x_2` are two uncertainties. We will assume that both parameters are Gaussians with :math:`\mu=1` and :math:`\sigma=2`. Our objective is to compute the mean and variance in the output. We start by defining our computational model

.. code::

	def rosenbrock_fun(x):
    		return (1 - x[0])**2 + 100*(x[1] - x[0]**2)**2

Next, we set the number of evaluation points in each direction. Lets opt for 4 points in the first direction and 7 points in the second direction. Using a tensor grid, this results in 28 points.

.. code::

	mu = 1
	sigma = 2
	variance = sigma**2
	x1 = Parameter(distribution="Gaussian", shape_parameter_A=mu, shape_parameter_B=variance, order=3)
	x2 = Parameter(distribution="Gaussian", shape_parameter_A=mu, shape_parameter_B=variance, order=6)
	parameters = [x1, x2]

